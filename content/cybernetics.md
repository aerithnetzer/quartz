---
id: cybernetic-hyperreality
aliases: []
tags: []
bibliography: ~/Desktop/My Library.bib
date: "2025-02-25"
draft: True
title: Towards a Theory of Cybernetic Hyperreality
---

How does raw data become models and then become atoms of cognition and then become control systems? 


Raw data -> Abstractions-in-themselves. The bits are abstracted from electrons quickly turning on and off which are then abstracted to "words" which are then abstracted to represent language or mathematics.

Models -> Then method of enforcing cognition on data. Models are used to take the many datas, and transform them into something that allows that data to be cognized by humans.

Cognizable Models -> The mental model that we enforce on models. How we create reality from the models. As is well-understood, models can be inherently biased or discriminatory --- in accident or deliberation --- and these perhaps biased or discriminatory models then create or reinvigorate the biases.

To be sure, biases against races or genders did not begin in the information age, but merely serves to _reinforce_ the previous mental models.

Current (popular in the lay media) talk about the ethics of "Artificial Intelligence" is either dominated by techno-capitalists with no training in ethics, or bioethics professors who have no training in programming. It is a relatively trivial task to quantify that a model is biased, racist, transphobic, etc., but it is a different beast entirely to understand how these models are deployed as self-referential justifications for the intractability of capitalism, the enforcement of control systems, and the imposition of simulacra onto reality.

## The Model

> [...] if the model is to take every variety of form, then the matter in which the model is fashioned will not be duly prepared, unless it is formless, and free from the impress of any of those shapes which it is hereafter to receive from without.

_Plato's Timaeus_

There is a certain vocabulary that we must define if we are to proceed diligently in this analysis, and no work of philosophy is complete without a discussion of the logic that is inscribed to all works. Logic, we maintain, is merely abstraction of _phenomena_. Looking to symbolic logic, we see that `a and ~a` cannot be true at the same time. This leads us to the abstraction, the abstraction that is produced from the sentence "`a and ~a` cannot be true at the same time" is meant to produce a cognition that a thing, in the real world, cannot exist and not-exist at the same time. 

This logic now serves as a "model" for cognizing our phenomena. The idea that a man could exist and not-exist at once is disorienting, and obviously impossible, and this formalization `a and ~a` cannot be true at the same time is a model, an abstraction, from the underlying reality. In short, it is a rough abstraction of how reality works. Like physics, wherein the mathematics often used is a mere approximation of reality, we are able to abstract our numbers just enough so that the numbers are not too cumbersome to consider, but accurate enough so that we can be predictive in our models.

The model is an demiurgical imposition of "humanizing" materia being the sense-experience of the being doing the imposition. This being is anything that is capable of imposing logic. Logic is the imposition of comprehension onto the materia. It enforces and holds the sense-data in its mainframe through abstraction.

Models are, in a sense, a novel language used as _lingua franca_ between the human cognition (sense-data) and the computational model of "cognition" (machine-data). These models are then used, by human cognition, as a "map" of reality. These models are human-intuitive, and as computer models inherently attempt to make "sense" of "sense-data" through the transliteration of this sense-data into binary code, and then back to sense-data through the medium of abstraction of computer-data.

Let us use a simple model as an example. We---that is to say humans,---collect data about our surroundings using data-collection methods, say, a census of a certain geopolitical entity. This recording of data, the very transcription of what the census-taker sees into a machine-readable format, is the translation between the sense-data and the computer-data. This computer-held data can then be used to create descriptive or predictive models of the computational data, and therefore, by transitive property, the model is, through the medium of computational abstraction, a "map" to the sense-data. This human-readable and intuitable map is then used to draw conclusions about the sense-data that we have collected.

Herein lies the seed at the center of this inquiry; we privilege the abstracted models, a filtered phenomena, over the Real. The fundamental truth of the matter is that we must make abstractions to use computer models, and these abstractions, necessarily, lose focus, introduce noise, are made less Real. This is not to say that these models are valuable for the pursuit of physical sciences. The nature of atoms and their impact, while greatly needed in the advancement of medical and physical science, bears little consequence to the political machinations with which machines control the lives of people. That is to say, when we gain complexity in experience, the more data from the Real is lost to the abstraction of models.

## Hyperreality and Models

The epigraph attributed to Borges in Baudrillard's _Simulacra and Simulation_ needs little introduction, and is good shorthand aid in understanding the hyperreal. Baudrillards definition of Hyperreality includes the creation of models of our real, "without origin or reality." These models, though clearly do have an origin. They are built from the synthesis of sense-data and the transliteration into the machine. In this sense, there is a ghost of sense-data in the machine. Something that is not quite human, but at the same time, far _too_ human. The sense-data has been pared down to mere representation, without substance. It is a mere image of the thing, without the thing itself. The origin of the models, the sense-data, through transliteration into machine-data, becomes un-real, unsubstantiated, un-sensed. It is no longer sense, but objective logic. In this moment, the subjective becomes objective, becomes unmediated through experience and through all-too-human lenses. The data points on the page, one an experience, has been reduced to a mere shadow of the once-substantive experience.

This process, the translation between the sense-data and the machine-data, leads some to the false perception that data held by computers, or the models that use that data, are infallible. As we established above, though, certain elements of sense-data are sacrificed in favor of machine intelligibility. Let us remember the old IBM adage, "A computer can never be held accountable, therefore, a computer must never make a management decision." As we dive deeper into "data-driven" societies, our decisions, desires, wants, needs, passions, hatred, it driven not by human emotion, but by the simplified nature of machine-data. It has stripped away the human experience. The machine is a cold, unfeeling thing. We must not fool ourselves that it is not.

